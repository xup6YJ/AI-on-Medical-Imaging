{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import numpy as np\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "import torchio as tio\n",
    "\n",
    "from util.logconf import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nibabel\n",
    "# !pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0226311\n",
      "/home/yingchihlin/Documents/Code/AISD/AISD.train/0226311\n",
      "/home/yingchihlin/Documents/Code/AISD/AISD.train/0226311/CT.nii.gz\n"
     ]
    }
   ],
   "source": [
    "#id list\n",
    "train_data_path = '/home/yingchihlin/Documents/Code/AISD/AISD.train'\n",
    "id_list = os.listdir(train_data_path)\n",
    "print(id_list[0])\n",
    "\n",
    "os.path.join(train_data_path, id_list[0])\n",
    "img_files = os.listdir(os.path.join(train_data_path, id_list[0]))\n",
    "print(os.path.join(train_data_path, id_list[0]))\n",
    "img_files\n",
    "\n",
    "t_file = ('CT.nii.gz', 'mask.nii.gz')\n",
    "print(os.path.join(train_data_path, id_list[0], t_file[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mask.nii.gz', 'ICV.nii.gz', 'CT_ss.nii.gz', 'mask_clip.nii.gz', 'CT.nii.gz']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 20)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0: CT, 1: Mask\n",
    "filename = os.path.join(train_data_path, id_list[0], t_file[0])\n",
    "\n",
    "img = nib.load(filename)\n",
    "img.shape\n",
    "\n",
    "data = img.get_fdata()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "uid = '0226311'\n",
    "uid = id_list[0]\n",
    "mhd_data_path = glob.glob('/home/yingchihlin/Documents/Code/AISD/AISD.train/{}/CT.nii.gz'.format(uid))[0]\n",
    "\n",
    "\n",
    "img = nib.load(mhd_data_path)\n",
    "data = img.get_fdata()\n",
    "data.shape\n",
    "\n",
    "mhd_mask_path = mhd_path = glob.glob('/home/yingchihlin/Documents/Code/AISD/AISD.train/{}/mask.nii.gz'.format(uid))[0]\n",
    "img = nib.load(mhd_mask_path)\n",
    "mask = img.get_fdata()\n",
    "mask.shape\n",
    "\n",
    "#clip\n",
    "data.clip(-1000, 1000, data)\n",
    "data\n",
    "\n",
    "positive_indexes = (mask.sum(axis=(0,1)).nonzero()[0].tolist())\n",
    "positive_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0226311', 6),\n",
       " ('0226311', 11),\n",
       " ('0226311', 12),\n",
       " ('0226311', 13),\n",
       " ('0226311', 14),\n",
       " ('0226311', 15)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list = []\n",
    "sample_list += [(uid, slice_ndx) for slice_ndx in positive_indexes]\n",
    "sample_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 512, 512)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.moveaxis(data, -1, 0)\n",
    "# data = data.permute(1, 2, 0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0226311 11\n",
      "torch.Size([7, 512, 512])\n",
      "8 15\n",
      "torch.Size([1, 512, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndx = 1\n",
    "contextSlices_count = 3\n",
    "series_uid, slice_ndx = sample_list[ndx % len(sample_list)]\n",
    "print(series_uid, slice_ndx)\n",
    "ct_t = torch.zeros((contextSlices_count * 2 + 1, 512, 512))\n",
    "print(ct_t.shape)\n",
    "start_ndx = slice_ndx - contextSlices_count\n",
    "end_ndx = slice_ndx + contextSlices_count + 1\n",
    "print(start_ndx, end_ndx)\n",
    "\n",
    "i = 0\n",
    "context_ndx = 8\n",
    "context_ndx = max(context_ndx, 0)\n",
    "context_ndx = min(context_ndx, data.shape[2] - 1)\n",
    "# print(context_ndx)\n",
    "\n",
    "# print(data.shape)\n",
    "# print(data[context_ndx].shape)\n",
    "# ct_t[i] = torch.from_numpy(data[context_ndx].astype(np.float32))\n",
    "# print(ct_t[i])\n",
    "\n",
    "\n",
    "for i, context_ndx in enumerate(range(start_ndx, end_ndx)):\n",
    "    context_ndx = max(context_ndx, 0)\n",
    "    context_ndx = min(context_ndx, data.shape[2] - 1)\n",
    "    ct_t[i] = torch.from_numpy(data[context_ndx].astype(np.float32))\n",
    "\n",
    "# CTs are natively expressed in https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "# HU are scaled oddly, with 0 g/cc (air, approximately) being -1000 and 1 g/cc (water) being 0.\n",
    "# The lower bound gets rid of negative density stuff used to indicate out-of-FOV\n",
    "# The upper bound nukes any weird hotspots and clamps bone down\n",
    "\n",
    "ct_t.clamp_(-1000, 1000)\n",
    "\n",
    "mask = np.moveaxis(mask, -1, 0)\n",
    "pos_t = torch.from_numpy(mask[slice_ndx]).unsqueeze(0)\n",
    "print(pos_t.shape)\n",
    "pos_t\n",
    "\n",
    "# pos_t = torch.from_numpy(ct.positive_mask[slice_ndx]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "\n",
    "def getCtSample(uid):\n",
    "    #data\n",
    "    mhd_data_path = mhd_path = glob.glob('/home/yingchihlin/Documents/Code/AISD/AISD.train/{}/CT.nii.gz'.format(uid))[0]\n",
    "    img = nib.load(mhd_data_path)\n",
    "    data = img.get_fdata()\n",
    "    data = np.moveaxis(data, -1, 0)\n",
    "    data.clip(-1000, 1000, data)\n",
    "\n",
    "    #mask\n",
    "    mhd_mask_path = mhd_path = glob.glob('/home/yingchihlin/Documents/Code/AISD/AISD.train/{}/mask.nii.gz'.format(uid))[0]\n",
    "    img = nib.load(mhd_mask_path)\n",
    "    mask = img.get_fdata()\n",
    "    mask = np.moveaxis(mask, -1, 0)\n",
    "\n",
    "    return data, mask\n",
    "\n",
    "\n",
    "class CtDataset(Dataset):\n",
    "    def __init__(self, uid, validation = False, val_stride = 5, contextSlices_count=3, fullCt_bool=True, id_list = id_list):\n",
    "\n",
    "        self.contextSlices_count = contextSlices_count\n",
    "        self.fullCt_bool = fullCt_bool\n",
    "        self.series_list = id_list\n",
    "\n",
    "        if  validation:\n",
    "            assert val_stride > 0, val_stride\n",
    "            self.series_list = self.series_list[::val_stride]\n",
    "            assert self.series_list\n",
    "        elif val_stride > 0:\n",
    "            del self.series_list[::val_stride]\n",
    "            assert self.series_list\n",
    "\n",
    "        self.sample_list = []\n",
    "        for series_uid in self.series_list:\n",
    "            # print(series_uid)\n",
    "            data, mask = getCtSample(series_uid)\n",
    "            \n",
    "            # positive slices\n",
    "            positive_indexes = (mask.sum(axis=(0,1)).nonzero()[0].tolist())\n",
    "\n",
    "            if self.fullCt_bool:\n",
    "                self.sample_list += [(series_uid, slice_ndx)\n",
    "                                     for slice_ndx in range(int(data.shape[0]))]\n",
    "            else:\n",
    "                self.sample_list += [(series_uid, slice_ndx)\n",
    "                                     for slice_ndx in positive_indexes]\n",
    "\n",
    "\n",
    "        logging.info(\"{!r}: {} {} series, {} slices\".format(\n",
    "            self,\n",
    "            len(self.series_list),\n",
    "            {None: 'general', False: 'training', True: 'validation'}[validation],\n",
    "            len(self.sample_list)\n",
    "        ))\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.sample_list)\n",
    "\n",
    "        def __getitem__(self, ndx):\n",
    "            series_uid, slice_ndx = self.sample_list[ndx % len(self.sample_list)]\n",
    "            return self.getitem_fullSlice(series_uid, slice_ndx)\n",
    "\n",
    "        def getitem_fullSlice(self, series_uid, slice_ndx):\n",
    "            ct, ct_mask = getCtSample(series_uid)\n",
    "\n",
    "            #Full Slice\n",
    "            if fullCt_bool:\n",
    "                ct_t = ct\n",
    "\n",
    "                # CTs are natively expressed in https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "                # HU are scaled oddly, with 0 g/cc (air, approximately) being -1000 and 1 g/cc (water) being 0.\n",
    "                # The lower bound gets rid of negative density stuff used to indicate out-of-FOV\n",
    "                # The upper bound nukes any weird hotspots and clamps bone down\n",
    "                ct_t.clamp_(-1000, 1000)\n",
    "\n",
    "                pos_t = torch.from_numpy(ct_mask[slice_ndx]).unsqueeze(0)\n",
    "\n",
    "            else:\n",
    "                ct_t = torch.zeros((self.contextSlices_count * 2 + 1, 512, 512))\n",
    "\n",
    "                start_ndx = slice_ndx - self.contextSlices_count\n",
    "                end_ndx = slice_ndx + self.contextSlices_count + 1\n",
    "                for i, context_ndx in enumerate(range(start_ndx, end_ndx)):\n",
    "                    context_ndx = max(context_ndx, 0)\n",
    "                    context_ndx = min(context_ndx, ct.shape[2] - 1)\n",
    "                    ct_t[i] = torch.from_numpy(ct[context_ndx].astype(np.float32))\n",
    "\n",
    "                ct_t.clamp_(-1000, 1000)\n",
    "\n",
    "                pos_t = torch.from_numpy(ct_mask[slice_ndx]).unsqueeze(0)\n",
    "\n",
    "            return ct_t, pos_t, series_uid, slice_ndx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 13:51:48,942 INFO     pid:689774 root:051:__init__ <__main__.CtDataset object at 0x7f177d55f700>: 276 training series, 7465 slices\n"
     ]
    }
   ],
   "source": [
    "dataset = CtDataset(id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TrainingCtDataset(CtDataset):\n",
    "    def __init__(self, uid, validation=False, val_stride=5, contextSlices_count=3, fullCt_bool=False, id_list=...):\n",
    "        super().__init__(uid, validation, val_stride, contextSlices_count, fullCt_bool, id_list)\n",
    "\n",
    "        self.ratio_int = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return 346*(1-self.val_stride)/self.val_stride\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.pos_list[ndx % len(self.pos_list)]\n",
    "        return self.getitem_trainingCrop(candidateInfo_tup)\n",
    "\n",
    "    def getitem_trainingCrop(self, candidateInfo_tup):\n",
    "        ct_a, pos_a, center_irc = getCtRawCandidate(\n",
    "            candidateInfo_tup.series_uid,\n",
    "            candidateInfo_tup.center_xyz,\n",
    "            (7, 96, 96),\n",
    "        )\n",
    "        pos_a = pos_a[3:4]  #middle mask slice as the training label\n",
    "\n",
    "        row_offset = random.randrange(0,32)\n",
    "        col_offset = random.randrange(0,32)\n",
    "        ct_t = torch.from_numpy(ct_a[:, row_offset:row_offset+64,\n",
    "                                     col_offset:col_offset+64]).to(torch.float32)\n",
    "        pos_t = torch.from_numpy(pos_a[:, row_offset:row_offset+64,\n",
    "                                       col_offset:col_offset+64]).to(torch.long)\n",
    "\n",
    "        slice_ndx = center_irc.index\n",
    "\n",
    "        return ct_t, pos_t, candidateInfo_tup.series_uid, slice_ndx\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6913a215bbcc3bc7ae5e7590d1ced35ed5310329dabd281eb0a320ee4e5a02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
