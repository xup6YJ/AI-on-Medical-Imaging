{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BraveNet3D\n",
    "\n",
    "#Encoder\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#kernels and stride to 3 × 3 × 3 and 1 for convolutions and 2 × 2 × 2 and 2 for max-pooling\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "    x = self.batch_norm(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, model_depth = 4, pool_size = 2):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.root_feat_maps = 16\n",
    "    self.num_conv_block = 2\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth):\n",
    "      feat_map_channels = 2**(depth+1)*self.root_feat_maps #32, 64, 128, 256\n",
    "      \n",
    "\n",
    "      for i in range(self.num_conv_block):\n",
    "        if depth == 0:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels) \n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "        else:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "      if depth == model_depth - 1:  #depth = 3\n",
    "        break\n",
    "      else:\n",
    "        nn.MaxPool3d\n",
    "        self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2)\n",
    "        self.module_dict['max_pooling_{}'.format(depth)] = self.pooling\n",
    "\n",
    "    self.module_dict2 = self.module_dict\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    print ('------Encoding------') \n",
    "    down_sampling_feature = []\n",
    "    down_sampling_feature2 = []\n",
    "    for k, op in self.module_dict.items():\n",
    "      if k.startswith('conv'):\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "        if k.endswith('1'):\n",
    "          down_sampling_feature.append(x)\n",
    "\n",
    "      else:\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "\n",
    "    for k, op in self.module_dict2.items():\n",
    "        if k.startswith('conv'):\n",
    "            y = op(y)\n",
    "            if k.endswith('1'):\n",
    "                down_sampling_feature2.append(y)\n",
    "        else:\n",
    "            y = op(y)\n",
    "\n",
    "    return down_sampling_feature, down_sampling_feature2\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     inputs_low = torch.randn(1, 1, 8, 64, 64)\n",
    "#     inputs_low = inputs_low.cuda()\n",
    "\n",
    "#     inputs_high = torch.randn(1, 1, 8, 64, 64)\n",
    "#     inputs_high = inputs_high.cuda()\n",
    "#     # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "#     encoder = Encoder(1)\n",
    "\n",
    "#     # print(encoder)\n",
    "#     encoder.cuda()\n",
    "\n",
    "\n",
    "#     d_low, d_high = encoder(inputs_low, inputs_high)\n",
    "#     # print('the shape of output = ', x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = Encoder(1)\n",
    "# print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "\n",
    "class ConvTranspose(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,\n",
    "    stride=stride, padding=padding, output_padding = output_padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return(self.conv3d_transpose(x))\n",
    "\n",
    "class ConvBlock_One_ReLu(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0):\n",
    "    super(ConvBlock_One_ReLu, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class ConvBlock_One(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0):\n",
    "    super(ConvBlock_One, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv3D(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "# operation:  conv_2_1 output shape:  torch.Size([1, 128, 2, 16, 16]) -> 8*64*64\n",
    "# operation:  conv_1_1 output shape:  torch.Size([1, 64, 4, 32, 32]) -> 8*64*64\n",
    "# operation:  final_conv output shape:  torch.Size([1, 1, 8, 64, 64])\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, out_channels, model_depth = 4):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.num_conv_blocks = 2\n",
    "    self.num_feat_maps = 16\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth-1, -1, -1): #3, 2, 1, 0\n",
    "\n",
    "      feat_map_channels = 2**(depth+1)*self.num_feat_maps #256 ,128, 64, 32\n",
    "\n",
    "      if depth == 3:\n",
    "        for i in range(self.num_conv_blocks):\n",
    "          if i == 0:\n",
    "            self.conv_one = ConvBlock_One_ReLu(feat_map_channels*2, out_channels=feat_map_channels)\n",
    "            self.module_dict['conv_one_{}_{}'.format(depth, i)] = self.conv_one\n",
    "          else:\n",
    "            self.conv_one = ConvBlock_One_ReLu(feat_map_channels, out_channels=feat_map_channels)\n",
    "            self.module_dict['conv_one_{}_{}'.format(depth, i)] = self.conv_one\n",
    "\n",
    "        self.deconv = ConvTranspose(in_channels=feat_map_channels, out_channels=feat_map_channels) #256\n",
    "        self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "\n",
    "      else:  #depth = 2, 1, 0 feat_map_channels = 128, 64, 32\n",
    "        for i in range(self.num_conv_blocks):\n",
    "          if i == 0:\n",
    "            self.conv_block = ConvBlock(in_channels=feat_map_channels*4, out_channels=feat_map_channels) #512/128, 256/64, 128/32\n",
    "            self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "          else:\n",
    "            self.conv_block = ConvBlock(in_channels=feat_map_channels, out_channels=feat_map_channels) #128/128, 64/64, 32/32\n",
    "            self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "\n",
    "            if depth in (1,2):\n",
    "              self.upsample = nn.Upsample(scale_factor=depth*2, mode='trilinear')\n",
    "              self.module_dict['upsample{}'.format(depth)] = self.upsample\n",
    "              self.conv_block_sig = ConvBlock_One(in_channels=feat_map_channels, out_channels=1) #128/1, 64/1, 32/1\n",
    "              self.module_dict['conv_one_output{}'.format(depth)] = self.conv_block_sig\n",
    "\n",
    "        if depth != 0:\n",
    "          self.deconv = ConvTranspose(in_channels=feat_map_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "\n",
    "      if depth == 0:\n",
    "        self.final_conv = ConvBlock_One(in_channels=feat_map_channels, out_channels=out_channels)\n",
    "        self.module_dict['final_conv'] = self.final_conv\n",
    "\n",
    "\n",
    "# operation:  conv_2_1 output shape:  torch.Size([1, 128, 2, 16, 16]) -> 1*128*8*64*64 -> 1*1*8*64*64\n",
    "# operation:  conv_1_1 output shape:  torch.Size([1, 64, 4, 32, 32]) -> 1*64*8*64*64 -> 1*1*8*64*64\n",
    "# operation:  final_conv output shape:  torch.Size([1, 1, 8, 64, 64])\n",
    "\n",
    "  def forward(self, down_sampling_feature, down_sampling_feature2):\n",
    "\n",
    "    final_feature = {}\n",
    "    print ('------Decoding------') \n",
    "\n",
    "    x = torch.cat((down_sampling_feature[3], down_sampling_feature2[3]), dim = 1)\n",
    "    print ('operation: original input concatenate', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['conv_one_3_0'](x)\n",
    "    print ('operation: conv_one_3_0', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['conv_one_3_1'](x)\n",
    "    print ('operation: conv_one_3_1', 'output shape: ', x.shape) \n",
    "\n",
    "    x = self.module_dict['deconv_3'](x)\n",
    "    print ('operation: deconv_3', 'output shape: ', x.shape) \n",
    "    y = torch.cat((down_sampling_feature[2], down_sampling_feature2[2]), dim = 1) #2, 1, 0\n",
    "    print ('operation: input concatenate', 'output shape: ', y.shape) \n",
    "    x = torch.cat((x, y), dim = 1)\n",
    "    print ('operation: concatenate', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['conv_2_0'](x)\n",
    "    print ('operation: conv_2_0', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['dropout2'](x)\n",
    "    print ('operation: dropout2', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['conv_2_1'](x)\n",
    "    print ('operation: conv_2_1', 'output shape: ', x.shape) \n",
    "\n",
    "    #out1\n",
    "    print ('-------------------------------------------------') \n",
    "    x1 = self.module_dict['upsample2'](x)\n",
    "    print ('operation: upsample2', 'output shape: ', x1.shape) \n",
    "    x1 = self.module_dict['conv_one_output2'](x1)\n",
    "    print('Shape of output: ', x1.shape)\n",
    "    print ('-------------------------------------------------') \n",
    "\n",
    "    #dev\n",
    "    x = self.module_dict['deconv_2'](x)\n",
    "    print ('operation: deconv_2', 'output shape: ', x.shape) \n",
    "    y = torch.cat((down_sampling_feature[1], down_sampling_feature2[1]), dim = 1) #2, 1, 0\n",
    "    print ('operation: input concatenate', 'output shape: ', y.shape) \n",
    "    x = torch.cat((x, y), dim = 1)\n",
    "    print ('operation: concatenate', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['conv_1_0'](x)\n",
    "    print ('operation: conv_1_0', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['dropout1'](x)\n",
    "    print ('operation: dropout1', 'output shape: ', x.shape) \n",
    "    x = self.module_dict['conv_1_1'](x)\n",
    "    print ('operation: conv_1_1', 'output shape: ', x.shape) \n",
    "\n",
    "    #out2\n",
    "    print ('-------------------------------------------------') \n",
    "    x2 = self.module_dict['upsample1'](x)\n",
    "    print ('operation: upsample1', 'output shape: ', x2.shape) \n",
    "    x2 = self.module_dict['conv_one_output1'](x2)\n",
    "    print('Shape of output: ', x2.shape)\n",
    "    print ('-------------------------------------------------') \n",
    "\n",
    "    #dev\n",
    "    x = self.module_dict['deconv_1'](x)\n",
    "    print ('operation: deconv_1', 'output shape: ', x.shape) \n",
    "    y = torch.cat((down_sampling_feature[0], down_sampling_feature2[0]), dim = 1) #2, 1, 0\n",
    "    print ('operation: input concatenate', 'output shape: ', y.shape) \n",
    "    x = torch.cat((x, y), dim = 1)\n",
    "    print ('operation: concatenate', 'output shape: ', x.shape)\n",
    "    x = self.module_dict['conv_0_0'](x)\n",
    "    print ('operation: conv_0_0', 'output shape: ', x.shape)\n",
    "    x = self.module_dict['dropout0'](x)\n",
    "    print ('operation: dropout0', 'output shape: ', x.shape)\n",
    "    x = self.module_dict['conv_0_1'](x)\n",
    "    print ('operation: conv_0_1', 'output shape: ', x.shape)\n",
    "\n",
    "    x = self.module_dict['final_conv'](x)\n",
    "    print ('-------------------------------------------------') \n",
    "    print('Shape of output: ', x.shape)\n",
    "\n",
    "    pred1 = torch.sigmoid(x)\n",
    "    pred2 = torch.sigmoid(x1)\n",
    "    pred3 = torch.sigmoid(x2)\n",
    "\n",
    "    return pred1, pred2, pred3\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n",
    "#     decoder = Decoder(1)\n",
    "#     decoder.cuda()\n",
    "#     x = decoder(d_low, d_high)\n",
    "    \n",
    "#     print('the shape of output = ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 'conv_2_1'\n",
    "# k in ('conv_2_1','conv_1_1')\n",
    "# 'layer_{}'.format(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (conv_one_3_0): ConvBlock_One_ReLu(\n",
       "      (conv3D): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (conv_one_3_1): ConvBlock_One_ReLu(\n",
       "      (conv3D): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (deconv_3): ConvTranspose(\n",
       "      (conv3d_transpose): ConvTranspose3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "    (conv_2_0): ConvBlock(\n",
       "      (conv3D): Conv3d(512, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout2): Dropout3d(p=0.5, inplace=False)\n",
       "    (conv_2_1): ConvBlock(\n",
       "      (conv3D): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (upsample2): Upsample(scale_factor=4.0, mode=trilinear)\n",
       "    (conv_one_output2): ConvBlock_One(\n",
       "      (conv3D): Conv3d(128, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (deconv_2): ConvTranspose(\n",
       "      (conv3d_transpose): ConvTranspose3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "    (conv_1_0): ConvBlock(\n",
       "      (conv3D): Conv3d(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout1): Dropout3d(p=0.5, inplace=False)\n",
       "    (conv_1_1): ConvBlock(\n",
       "      (conv3D): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (upsample1): Upsample(scale_factor=2.0, mode=trilinear)\n",
       "    (conv_one_output1): ConvBlock_One(\n",
       "      (conv3D): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (deconv_1): ConvTranspose(\n",
       "      (conv3d_transpose): ConvTranspose3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "    (conv_0_0): ConvBlock(\n",
       "      (conv3D): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout0): Dropout3d(p=0.5, inplace=False)\n",
       "    (conv_0_1): ConvBlock(\n",
       "      (conv3D): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (final_conv): ConvBlock_One(\n",
       "      (conv3D): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (conv_one): ConvBlock_One_ReLu(\n",
       "    (conv3D): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (deconv): ConvTranspose(\n",
       "    (conv3d_transpose): ConvTranspose3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  )\n",
       "  (conv_block): ConvBlock(\n",
       "    (conv3D): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (dropout): Dropout3d(p=0.5, inplace=False)\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=trilinear)\n",
       "  (conv_block_sig): ConvBlock_One(\n",
       "    (conv3D): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (final_conv): ConvBlock_One(\n",
       "    (conv3D): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(1)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Encoding------\n",
      "operation:  conv_0_0 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation:  dropout0 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation:  conv_0_1 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation:  max_pooling_0 output shape:  torch.Size([1, 32, 4, 32, 32])\n",
      "operation:  conv_1_0 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation:  dropout1 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation:  conv_1_1 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation:  max_pooling_1 output shape:  torch.Size([1, 64, 2, 16, 16])\n",
      "operation:  conv_2_0 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation:  dropout2 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation:  conv_2_1 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation:  max_pooling_2 output shape:  torch.Size([1, 128, 1, 8, 8])\n",
      "operation:  conv_3_0 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "operation:  dropout3 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "operation:  conv_3_1 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "------Decoding------\n",
      "operation: original input concatenate output shape:  torch.Size([1, 512, 1, 8, 8])\n",
      "operation: conv_one_3_0 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "operation: conv_one_3_1 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "operation: deconv_3 output shape:  torch.Size([1, 256, 2, 16, 16])\n",
      "operation: input concatenate output shape:  torch.Size([1, 256, 2, 16, 16])\n",
      "operation: concatenate output shape:  torch.Size([1, 512, 2, 16, 16])\n",
      "operation: conv_2_0 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation: dropout2 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation: conv_2_1 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "-------------------------------------------------\n",
      "operation: upsample2 output shape:  torch.Size([1, 128, 8, 64, 64])\n",
      "Shape of output:  torch.Size([1, 1, 8, 64, 64])\n",
      "-------------------------------------------------\n",
      "operation: deconv_2 output shape:  torch.Size([1, 128, 4, 32, 32])\n",
      "operation: input concatenate output shape:  torch.Size([1, 128, 4, 32, 32])\n",
      "operation: concatenate output shape:  torch.Size([1, 256, 4, 32, 32])\n",
      "operation: conv_1_0 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation: dropout1 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation: conv_1_1 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "-------------------------------------------------\n",
      "operation: upsample1 output shape:  torch.Size([1, 64, 8, 64, 64])\n",
      "Shape of output:  torch.Size([1, 1, 8, 64, 64])\n",
      "-------------------------------------------------\n",
      "operation: deconv_1 output shape:  torch.Size([1, 64, 8, 64, 64])\n",
      "operation: input concatenate output shape:  torch.Size([1, 64, 8, 64, 64])\n",
      "operation: concatenate output shape:  torch.Size([1, 128, 8, 64, 64])\n",
      "operation: conv_0_0 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation: dropout0 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation: conv_0_1 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "-------------------------------------------------\n",
      "Shape of output:  torch.Size([1, 1, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class BraveNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, model_depth = 4):\n",
    "        super(BraveNet, self).__init__()\n",
    "        self.encoder = Encoder(in_channels=in_channels, model_depth=model_depth)\n",
    "        self.decoder = Decoder(out_channels=out_channels, model_depth=model_depth)\n",
    "        # if final_activation == 'sigmoid':\n",
    "        #     self.f_activation = nn.Sigmoid()\n",
    "        # else:\n",
    "        #     self.f_activation = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        d_features, d_features2 = self.encoder(x, y)\n",
    "        p1, p2, p3 = self.decoder(d_features, d_features2)\n",
    "        # x = self.f_activation(x)\n",
    "        # print(\"Final output shape: \", x.shape)\n",
    "\n",
    "        return p1, p2, p3\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs_low = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_low = inputs_low.cuda()\n",
    "\n",
    "    inputs_high = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_high = inputs_high.cuda()\n",
    "\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    model = BraveNet(in_channels=1, out_channels=1)\n",
    "    model.cuda()\n",
    "\n",
    "    p1, p2, p3 = model(inputs_low, inputs_high)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6913a215bbcc3bc7ae5e7590d1ced35ed5310329dabd281eb0a320ee4e5a02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
