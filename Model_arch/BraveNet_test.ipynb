{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.batch_norm(self.conv3D(x))\n",
    "    x = F.relu(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, model_depth = 4, pool_size = 2):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.root_feat_maps = 16\n",
    "    self.num_conv_block = 2\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth):\n",
    "      feat_map_channels = 2**(depth+1)*self.root_feat_maps #2*16, 4*16, 8*16, 16*16\n",
    "\n",
    "      for i in range(self.num_conv_block):\n",
    "        if depth == 0:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels) \n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "        else:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "\n",
    "      if depth == model_depth - 1:  #depth = 3\n",
    "        break\n",
    "      else:\n",
    "        self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2, padding=0)\n",
    "        self.module_dict['max_pooling_{}'.format(depth)] = self.pooling\n",
    "\n",
    "  def forward(self, x):\n",
    "    down_sampling_feature = []\n",
    "    for k, op in self.module_dict.items():\n",
    "      # print('k: ', k, 'op: ', op)\n",
    "\n",
    "      if k.startswith('conv'):\n",
    "        x = op(x)\n",
    "        # print (k, x.shape)\n",
    "        if k.endswith('1'):\n",
    "          down_sampling_feature.append(x)\n",
    "\n",
    "      elif k.startswith('max_pooling'):\n",
    "        x = op(x)\n",
    "        # print(k, x.shape)\n",
    "\n",
    "    return x, down_sampling_feature\n",
    "\n",
    "class ConvTranspose(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,\n",
    "    stride=stride, padding=padding, output_padding = output_padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return(self.conv3d_transpose(x))\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, out_channels, model_depth = 4):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.num_conv_blocks = 2\n",
    "    self.num_feat_maps = 16\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth-2, -1, -1): #2, 1, 0\n",
    "      feat_map_channels = 2**(depth+1)*self.num_feat_maps #128, 64, 32\n",
    "      self.deconv = ConvTranspose(in_channels=feat_map_channels*4, out_channels=feat_map_channels*4) #512, 256, 128\n",
    "      self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "      for i in range(self.num_conv_blocks):\n",
    "        if i == 0:\n",
    "          self.conv = ConvBlock(in_channels=feat_map_channels*6, out_channels=feat_map_channels*2) #768/256, 384/128, 192/64\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv\n",
    "        else:\n",
    "          self.conv = ConvBlock(in_channels=feat_map_channels*2, out_channels=feat_map_channels*2) #256/256, 128/128, 64/64\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv\n",
    "      if depth == 0:\n",
    "        self.final_conv = ConvBlock(in_channels=feat_map_channels*2, out_channels=out_channels)\n",
    "        self.module_dict['final_conv'] = self.final_conv\n",
    "\n",
    "  def forward(self, x, down_sampling_feature):\n",
    "    for k, op in self.module_dict.items():\n",
    "      if k.startswith('deconv'):\n",
    "        x = op(x)\n",
    "        x = torch.cat((down_sampling_feature[int(k[-1])], x), dim = 1)\n",
    "      elif k.startswith('conv'):\n",
    "        x = op(x)\n",
    "      else:\n",
    "        x = op(x)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape:  torch.Size([1, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "class Unet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, model_depth = 4, final_activation = 'sigmoid'):\n",
    "        super(Unet3D, self).__init__()\n",
    "        self.encoder = Encoder(in_channels=in_channels, model_depth=model_depth)\n",
    "        self.decoder = Decoder(out_channels=out_channels, model_depth=model_depth)\n",
    "        if final_activation == 'sigmoid':\n",
    "            self.f_activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.f_activation = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, d_features = self.encoder(x)\n",
    "        x = self.decoder(x, d_features)\n",
    "        x = self.f_activation(x)\n",
    "        print(\"Final output shape: \", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = torch.randn(1, 1, 96, 96, 96)\n",
    "    inputs = inputs.cuda()\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    model = Unet3D(in_channels=1, out_channels=1)\n",
    "    model.cuda()\n",
    "\n",
    "    x_test = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  conv_0_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 1, 8, 64, 64])\n",
      "output torch.Size([1, 32, 8, 64, 64])\n",
      "k:  dropout0 op:  Dropout3d(p=0.5, inplace=False)\n",
      "input torch.Size([1, 32, 8, 64, 64])\n",
      "output torch.Size([1, 32, 8, 64, 64])\n",
      "k:  conv_0_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 32, 8, 64, 64])\n",
      "output torch.Size([1, 32, 8, 64, 64])\n",
      "k:  max_pooling_0 op:  MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "input torch.Size([1, 32, 8, 64, 64])\n",
      "output torch.Size([1, 32, 4, 32, 32])\n",
      "k:  conv_1_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 32, 4, 32, 32])\n",
      "output torch.Size([1, 64, 4, 32, 32])\n",
      "k:  dropout1 op:  Dropout3d(p=0.5, inplace=False)\n",
      "input torch.Size([1, 64, 4, 32, 32])\n",
      "output torch.Size([1, 64, 4, 32, 32])\n",
      "k:  conv_1_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 64, 4, 32, 32])\n",
      "output torch.Size([1, 64, 4, 32, 32])\n",
      "k:  max_pooling_1 op:  MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "input torch.Size([1, 64, 4, 32, 32])\n",
      "output torch.Size([1, 64, 2, 16, 16])\n",
      "k:  conv_2_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 64, 2, 16, 16])\n",
      "output torch.Size([1, 128, 2, 16, 16])\n",
      "k:  dropout2 op:  Dropout3d(p=0.5, inplace=False)\n",
      "input torch.Size([1, 128, 2, 16, 16])\n",
      "output torch.Size([1, 128, 2, 16, 16])\n",
      "k:  conv_2_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 128, 2, 16, 16])\n",
      "output torch.Size([1, 128, 2, 16, 16])\n",
      "k:  max_pooling_2 op:  MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "input torch.Size([1, 128, 2, 16, 16])\n",
      "output torch.Size([1, 128, 1, 8, 8])\n",
      "k:  conv_3_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 128, 1, 8, 8])\n",
      "output torch.Size([1, 256, 1, 8, 8])\n",
      "k:  dropout3 op:  Dropout3d(p=0.5, inplace=False)\n",
      "input torch.Size([1, 256, 1, 8, 8])\n",
      "output torch.Size([1, 256, 1, 8, 8])\n",
      "k:  conv_3_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 256, 1, 8, 8])\n",
      "output torch.Size([1, 256, 1, 8, 8])\n",
      "the shape of output =  torch.Size([1, 256, 1, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "#BraveNet\n",
    "\n",
    "#3D\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#kernels and stride to 3 × 3 × 3 and 1 for convolutions and 2 × 2 × 2 and 2 for max-pooling\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "    x = self.batch_norm(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, model_depth = 4, pool_size = 2):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.root_feat_maps = 16\n",
    "    self.num_conv_block = 2\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth):\n",
    "      feat_map_channels = 2**(depth+1)*self.root_feat_maps #32, 64, 128, 256\n",
    "      \n",
    "\n",
    "      for i in range(self.num_conv_block):\n",
    "        if depth == 0:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels) \n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "        else:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "      if depth == model_depth - 1:  #depth = 3\n",
    "        break\n",
    "      else:\n",
    "        nn.MaxPool3d\n",
    "        self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2)\n",
    "        self.module_dict['max_pooling_{}'.format(depth)] = self.pooling\n",
    "\n",
    "  def forward(self, x):\n",
    "    down_sampling_feature = []\n",
    "    for k, op in self.module_dict.items():\n",
    "      print('k: ', k, 'op: ', op)\n",
    "\n",
    "      if k.startswith('conv'):\n",
    "        print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        print ('output', x.shape)\n",
    "        if k.endswith('1'):\n",
    "          down_sampling_feature.append(x)\n",
    "\n",
    "      elif k.startswith('max_pooling'):\n",
    "        print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        print ('output', x.shape)\n",
    "        # print(k, x.shape)\n",
    "\n",
    "      else:\n",
    "        print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        print ('output', x.shape)\n",
    "\n",
    "    return x, down_sampling_feature\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs = inputs.cuda()\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    encoder = Encoder(1)\n",
    "    # print(encoder)\n",
    "    encoder.cuda()\n",
    "\n",
    "    x_test = encoder(inputs)\n",
    "    print('the shape of output = ', x_test[0].shape)\n",
    "\n",
    "# encoder = Encoder(1)\n",
    "# print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "#BraveNet\n",
    "\n",
    "#3D\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#kernels and stride to 3 × 3 × 3 and 1 for convolutions and 2 × 2 × 2 and 2 for max-pooling\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "    x = self.batch_norm(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, model_depth = 4, pool_size = 2):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.root_feat_maps = 16\n",
    "    self.num_conv_block = 2\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth):\n",
    "      feat_map_channels = 2**(depth+1)*self.root_feat_maps #32, 64, 128, 256\n",
    "      \n",
    "\n",
    "      for i in range(self.num_conv_block):\n",
    "        if depth == 0:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels) \n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "        else:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "      if depth == model_depth - 1:  #depth = 3\n",
    "        break\n",
    "      else:\n",
    "        nn.MaxPool3d\n",
    "        self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2)\n",
    "        self.module_dict['max_pooling_{}'.format(depth)] = self.pooling\n",
    "\n",
    "  def forward(self, x):\n",
    "    down_sampling_feature = []\n",
    "    for k, op in self.module_dict.items():\n",
    "      # print('k: ', k, 'op: ', op)\n",
    "\n",
    "      if k.startswith('conv'):\n",
    "        # print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        # print ('output', x.shape)\n",
    "        if k.endswith('1'):\n",
    "          down_sampling_feature.append(x)\n",
    "\n",
    "      else:\n",
    "        # print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        # print ('output', x.shape)\n",
    "        # print(k, x.shape)\n",
    "\n",
    "    return x, down_sampling_feature\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs_low = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_low = inputs.cuda()\n",
    "\n",
    "    inputs_high = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_high = inputs.cuda()\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    encoder1 = Encoder(1)\n",
    "    encoder2 = Encoder(1)\n",
    "    # print(encoder)\n",
    "    encoder1.cuda()\n",
    "    encoder2.cuda()\n",
    "\n",
    "    x_low, d_low = encoder1(inputs_low)\n",
    "    x_high, d_high = encoder2(inputs_high)\n",
    "    # print('the shape of output = ', x_test[0].shape)\n",
    "\n",
    "# encoder = Encoder(1)\n",
    "# print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "duplicate argument 'down_sampling_feature' in function definition (1191465602.py, line 63)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [55], line 63\u001b[0;36m\u001b[0m\n\u001b[0;31m    def forward(self, x, down_sampling_feature, down_sampling_feature):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m duplicate argument 'down_sampling_feature' in function definition\n"
     ]
    }
   ],
   "source": [
    "class ConvTranspose(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,\n",
    "    stride=stride, padding=padding, output_padding = output_padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return(self.conv3d_transpose(x))\n",
    "\n",
    "class ConvBlock_One(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 1, stride = 1, padding = 1):\n",
    "    super(ConvBlock_One, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, out_channels, model_depth = 4):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.num_conv_blocks = 2\n",
    "    self.num_feat_maps = 16\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth-1, -1, -1): #3, 2, 1, 0\n",
    "\n",
    "      feat_map_channels = 2**(depth+1)*self.num_feat_maps #256 ,128, 64, 32\n",
    "\n",
    "      if depth == 3:\n",
    "        for i in range(self.num_conv_blocks):\n",
    "          if i == 0:\n",
    "            self.conv_one = ConvBlock_One(feat_map_channels*2, out_channels=feat_map_channels)\n",
    "            self.module_dict['conv_one_{}_{}'.format(depth, i)] = self.conv_one\n",
    "          else:\n",
    "            self.conv_one = ConvBlock_One(feat_map_channels, out_channels=feat_map_channels)\n",
    "            self.module_dict['conv_one_{}_{}'.format(depth, i)] = self.conv_one\n",
    "\n",
    "        self.deconv = ConvTranspose(in_channels=feat_map_channels, out_channels=feat_map_channels) #256\n",
    "        self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "\n",
    "      else:  #depth = 2, 1, 0 feat_map_channels = 128, 64, 32\n",
    "        for i in range(self.num_conv_blocks):\n",
    "          if i == 0:\n",
    "            self.conv_block = ConvBlock(in_channels=feat_map_channels*4, out_channels=feat_map_channels) #512/128, 256/64, 128/32\n",
    "            self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "          else:\n",
    "            self.conv_block = ConvBlock(in_channels=feat_map_channels, out_channels=feat_map_channels) #128/128, 64/64, 32/32\n",
    "            self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "\n",
    "        if depth != 0:\n",
    "          self.deconv = ConvTranspose(in_channels=feat_map_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "\n",
    "      if depth == 0:\n",
    "        self.final_conv = ConvBlock_One(in_channels=feat_map_channels, out_channels=out_channels)\n",
    "        self.module_dict['final_conv'] = self.final_conv\n",
    "\n",
    "  def forward(self, x, down_sampling_feature):\n",
    "    for k, op in self.module_dict.items():\n",
    "      if k.startswith('deconv'):\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "        x = torch.cat((down_sampling_feature[int(k[-1])], x), dim = 1)\n",
    "        print ('operation: concat','output shape: ', x.shape) \n",
    "      elif k.startswith('conv'):\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "      else:\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "decoder = Decoder(1)\n",
    "decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6913a215bbcc3bc7ae5e7590d1ced35ed5310329dabd281eb0a320ee4e5a02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
