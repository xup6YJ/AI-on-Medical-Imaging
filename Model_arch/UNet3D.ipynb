{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.batch_norm(self.conv3D(x))\n",
    "    x = F.relu(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, model_depth = 4, pool_size = 2):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.root_feat_maps = 16\n",
    "    self.num_conv_block = 2\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth):\n",
    "      feat_map_channels = 2**(depth+1)*self.root_feat_maps #2*16, 4*16, 8*16, 16*16\n",
    "\n",
    "      for i in range(self.num_conv_block):\n",
    "        if depth == 0:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels) \n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "        else:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "\n",
    "      if depth == model_depth - 1:  #depth = 3\n",
    "        break\n",
    "      else:\n",
    "        self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2, padding=0)\n",
    "        self.module_dict['max_pooling_{}'.format(depth)] = self.pooling\n",
    "\n",
    "  def forward(self, x):\n",
    "    down_sampling_feature = []\n",
    "    for k, op in self.module_dict.items():\n",
    "      print('k: ', k, 'op: ', op)\n",
    "\n",
    "      if k.startswith('conv'):\n",
    "        print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        print ('output', x.shape)\n",
    "        # print (k, x.shape)\n",
    "        if k.endswith('1'):\n",
    "          down_sampling_feature.append(x)\n",
    "\n",
    "      elif k.startswith('max_pooling'):\n",
    "        print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        print ('output', x.shape)\n",
    "        # print(k, x.shape)\n",
    "\n",
    "    return x, down_sampling_feature\n",
    "\n",
    "class ConvTranspose(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,\n",
    "    stride=stride, padding=padding, output_padding = output_padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return(self.conv3d_transpose(x))\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, out_channels, model_depth = 4):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.num_conv_blocks = 2\n",
    "    self.num_feat_maps = 16\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth-2, -1, -1): #2, 1, 0\n",
    "      feat_map_channels = 2**(depth+1)*self.num_feat_maps #128, 64, 32\n",
    "      self.deconv = ConvTranspose(in_channels=feat_map_channels*4, out_channels=feat_map_channels*4) #512, 256, 128\n",
    "      self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "      for i in range(self.num_conv_blocks):\n",
    "        if i == 0:\n",
    "          self.conv = ConvBlock(in_channels=feat_map_channels*6, out_channels=feat_map_channels*2) #768/256, 384/128, 192/64\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv\n",
    "        else:\n",
    "          self.conv = ConvBlock(in_channels=feat_map_channels*2, out_channels=feat_map_channels*2) #256/256, 128/128, 64/64\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv\n",
    "      if depth == 0:\n",
    "        self.final_conv = ConvBlock(in_channels=feat_map_channels*2, out_channels=out_channels)\n",
    "        self.module_dict['final_conv'] = self.final_conv\n",
    "\n",
    "  def forward(self, x, down_sampling_feature):\n",
    "    for k, op in self.module_dict.items():\n",
    "      if k.startswith('deconv'):\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "        x = torch.cat((down_sampling_feature[int(k[-1])], x), dim = 1)\n",
    "        print ('concat shape1', down_sampling_feature[int(k[-1])].shape) \n",
    "        print ('operation: concat', 'output shape: ', x.shape) \n",
    "      elif k.startswith('conv'):\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "      else:\n",
    "        x = op(x)\n",
    "        print ('operation: ',k, 'output shape: ', x.shape) \n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (module_dict): ModuleDict(\n",
      "    (conv_0_0): ConvBlock(\n",
      "      (conv3D): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_0_1): ConvBlock(\n",
      "      (conv3D): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (max_pooling_0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv_1_0): ConvBlock(\n",
      "      (conv3D): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_1_1): ConvBlock(\n",
      "      (conv3D): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (max_pooling_1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv_2_0): ConvBlock(\n",
      "      (conv3D): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_2_1): ConvBlock(\n",
      "      (conv3D): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (max_pooling_2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv_3_0): ConvBlock(\n",
      "      (conv3D): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (conv_3_1): ConvBlock(\n",
      "      (conv3D): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "      (batch_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_block): ConvBlock(\n",
      "    (conv3D): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "    (batch_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pooling): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(1)\n",
    "print(encoder)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     inputs = torch.randn(1, 1, 8, 64, 64)\n",
    "#     inputs = inputs.cuda()\n",
    "#     # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "#     encoder = Encoder(1)\n",
    "#     # print(encoder)\n",
    "#     encoder.cuda()\n",
    "\n",
    "#     x_test = encoder(inputs)\n",
    "#     # print('the shape of output = ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     x_test = torch.randn(1, 1, 96, 96, 96)\n",
    "#     x_test = x_test.cuda()\n",
    "#     print('the shape of input = ', x_test.shape)\n",
    "\n",
    "#     encoder = Encoder(in_channels=1)\n",
    "#     encoder.cuda()\n",
    "#     print(encoder)\n",
    "#     x_test, h = encoder(x_test)\n",
    "\n",
    "#     db = Decoder(out_channels=1)\n",
    "#     db.cuda()\n",
    "#     x_test = db(x_test, h)\n",
    "\n",
    "#     print('the shape of output = ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  conv_0_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 1, 96, 96, 96])\n",
      "output torch.Size([1, 32, 96, 96, 96])\n",
      "k:  conv_0_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 32, 96, 96, 96])\n",
      "output torch.Size([1, 64, 96, 96, 96])\n",
      "k:  max_pooling_0 op:  MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "input torch.Size([1, 64, 96, 96, 96])\n",
      "output torch.Size([1, 64, 48, 48, 48])\n",
      "k:  conv_1_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 64, 48, 48, 48])\n",
      "output torch.Size([1, 64, 48, 48, 48])\n",
      "k:  conv_1_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 64, 48, 48, 48])\n",
      "output torch.Size([1, 128, 48, 48, 48])\n",
      "k:  max_pooling_1 op:  MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "input torch.Size([1, 128, 48, 48, 48])\n",
      "output torch.Size([1, 128, 24, 24, 24])\n",
      "k:  conv_2_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 128, 24, 24, 24])\n",
      "output torch.Size([1, 128, 24, 24, 24])\n",
      "k:  conv_2_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 128, 24, 24, 24])\n",
      "output torch.Size([1, 256, 24, 24, 24])\n",
      "k:  max_pooling_2 op:  MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "input torch.Size([1, 256, 24, 24, 24])\n",
      "output torch.Size([1, 256, 12, 12, 12])\n",
      "k:  conv_3_0 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 256, 12, 12, 12])\n",
      "output torch.Size([1, 256, 12, 12, 12])\n",
      "k:  conv_3_1 op:  ConvBlock(\n",
      "  (conv3D): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (batch_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "input torch.Size([1, 256, 12, 12, 12])\n",
      "output torch.Size([1, 512, 12, 12, 12])\n",
      "operation:  deconv_2 output shape:  torch.Size([1, 512, 24, 24, 24])\n",
      "concat shape1 torch.Size([1, 256, 24, 24, 24])\n",
      "operation: concat output shape:  torch.Size([1, 768, 24, 24, 24])\n",
      "operation:  conv_2_0 output shape:  torch.Size([1, 256, 24, 24, 24])\n",
      "operation:  conv_2_1 output shape:  torch.Size([1, 256, 24, 24, 24])\n",
      "operation:  deconv_1 output shape:  torch.Size([1, 256, 48, 48, 48])\n",
      "concat shape1 torch.Size([1, 128, 48, 48, 48])\n",
      "operation: concat output shape:  torch.Size([1, 384, 48, 48, 48])\n",
      "operation:  conv_1_0 output shape:  torch.Size([1, 128, 48, 48, 48])\n",
      "operation:  conv_1_1 output shape:  torch.Size([1, 128, 48, 48, 48])\n",
      "operation:  deconv_0 output shape:  torch.Size([1, 128, 96, 96, 96])\n",
      "concat shape1 torch.Size([1, 64, 96, 96, 96])\n",
      "operation: concat output shape:  torch.Size([1, 192, 96, 96, 96])\n",
      "operation:  conv_0_0 output shape:  torch.Size([1, 64, 96, 96, 96])\n",
      "operation:  conv_0_1 output shape:  torch.Size([1, 64, 96, 96, 96])\n",
      "operation:  final_conv output shape:  torch.Size([1, 1, 96, 96, 96])\n",
      "Final output shape:  torch.Size([1, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "class Unet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, model_depth = 4, final_activation = 'sigmoid'):\n",
    "        super(Unet3D, self).__init__()\n",
    "        self.encoder = Encoder(in_channels=in_channels, model_depth=model_depth)\n",
    "        self.decoder = Decoder(out_channels=out_channels, model_depth=model_depth)\n",
    "        if final_activation == 'sigmoid':\n",
    "            self.f_activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.f_activation = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, d_features = self.encoder(x)\n",
    "        x = self.decoder(x, d_features)\n",
    "        x = self.f_activation(x)\n",
    "        print(\"Final output shape: \", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = torch.randn(1, 1, 96, 96, 96)\n",
    "    inputs = inputs.cuda()\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    model = Unet3D(in_channels=1, out_channels=1)\n",
    "    model.cuda()\n",
    "\n",
    "    x_test = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _*_ coding: utf-8 _*_\n",
    "# # Author: Jielong\n",
    "# # @Time: 21/08/2019 15:52\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class ConvBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, k_size=3, stride=1, padding=1):\n",
    "#         super(ConvBlock, self).__init__()\n",
    "#         self.conv3d = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=k_size,\n",
    "#                                 stride=stride, padding=padding)\n",
    "#         self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.batch_norm(self.conv3d(x))\n",
    "#         # x = self.conv3d(x)\n",
    "#         x = F.elu(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class EncoderBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, model_depth=4, pool_size=2):\n",
    "#         super(EncoderBlock, self).__init__()\n",
    "#         self.root_feat_maps = 16\n",
    "#         self.num_conv_blocks = 2\n",
    "#         # self.module_list = nn.ModuleList()\n",
    "#         self.module_dict = nn.ModuleDict()\n",
    "#         for depth in range(model_depth):\n",
    "#             feat_map_channels = 2 ** (depth + 1) * self.root_feat_maps\n",
    "#             for i in range(self.num_conv_blocks):\n",
    "#                 # print(\"depth {}, conv {}\".format(depth, i))\n",
    "#                 if depth == 0:\n",
    "#                     # print(in_channels, feat_map_channels)\n",
    "#                     self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "#                     self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv_block\n",
    "#                     in_channels, feat_map_channels = feat_map_channels, feat_map_channels * 2\n",
    "#                 else:\n",
    "#                     # print(in_channels, feat_map_channels)\n",
    "#                     self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "#                     self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv_block\n",
    "#                     in_channels, feat_map_channels = feat_map_channels, feat_map_channels * 2\n",
    "#             if depth == model_depth - 1:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2, padding=0)\n",
    "#                 self.module_dict[\"max_pooling_{}\".format(depth)] = self.pooling\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         down_sampling_features = []\n",
    "#         for k, op in self.module_dict.items():\n",
    "#             if k.startswith(\"conv\"):\n",
    "#                 x = op(x)\n",
    "#                 print(k, x.shape)\n",
    "#                 if k.endswith(\"1\"):\n",
    "#                     down_sampling_features.append(x)\n",
    "#             elif k.startswith(\"max_pooling\"):\n",
    "#                 x = op(x)\n",
    "#                 print(k, x.shape)\n",
    "\n",
    "#         return x, down_sampling_features\n",
    "\n",
    "\n",
    "# class ConvTranspose(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, k_size=3, stride=2, padding=1, output_padding=1):\n",
    "#         super(ConvTranspose, self).__init__()\n",
    "#         self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels,\n",
    "#                                                    out_channels=out_channels,\n",
    "#                                                    kernel_size=k_size,\n",
    "#                                                    stride=stride,\n",
    "#                                                    padding=padding,\n",
    "#                                                    output_padding=output_padding)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.conv3d_transpose(x)\n",
    "\n",
    "\n",
    "# class DecoderBlock(nn.Module):\n",
    "#     def __init__(self, out_channels, model_depth=4):\n",
    "#         super(DecoderBlock, self).__init__()\n",
    "#         self.num_conv_blocks = 2\n",
    "#         self.num_feat_maps = 16\n",
    "#         # user nn.ModuleDict() to store ops\n",
    "#         self.module_dict = nn.ModuleDict()\n",
    "\n",
    "#         for depth in range(model_depth - 2, -1, -1):\n",
    "#             # print(depth)\n",
    "#             feat_map_channels = 2 ** (depth + 1) * self.num_feat_maps\n",
    "#             # print(feat_map_channels * 4)\n",
    "#             self.deconv = ConvTranspose(in_channels=feat_map_channels * 4, out_channels=feat_map_channels * 4)\n",
    "#             self.module_dict[\"deconv_{}\".format(depth)] = self.deconv\n",
    "#             for i in range(self.num_conv_blocks):\n",
    "#                 if i == 0:\n",
    "#                     self.conv = ConvBlock(in_channels=feat_map_channels * 6, out_channels=feat_map_channels * 2)\n",
    "#                     self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv\n",
    "#                 else:\n",
    "#                     self.conv = ConvBlock(in_channels=feat_map_channels * 2, out_channels=feat_map_channels * 2)\n",
    "#                     self.module_dict[\"conv_{}_{}\".format(depth, i)] = self.conv\n",
    "#             if depth == 0:\n",
    "#                 self.final_conv = ConvBlock(in_channels=feat_map_channels * 2, out_channels=out_channels)\n",
    "#                 self.module_dict[\"final_conv\"] = self.final_conv\n",
    "\n",
    "#     def forward(self, x, down_sampling_features):\n",
    "#         \"\"\"\n",
    "#         :param x: inputs\n",
    "#         :param down_sampling_features: feature maps from encoder path\n",
    "#         :return: output\n",
    "#         \"\"\"\n",
    "#         for k, op in self.module_dict.items():\n",
    "#             if k.startswith(\"deconv\"):\n",
    "#                 x = op(x)\n",
    "#                 x = torch.cat((down_sampling_features[int(k[-1])], x), dim=1)\n",
    "#             elif k.startswith(\"conv\"):\n",
    "#                 x = op(x)\n",
    "#             else:\n",
    "#                 x = op(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # x has shape of (batch_size, channels, depth, height, width)\n",
    "#     x_test = torch.randn(1, 1, 96, 96, 96)\n",
    "#     x_test = x_test.cuda()\n",
    "#     print(\"The shape of input: \", x_test.shape)\n",
    "\n",
    "#     encoder = EncoderBlock(in_channels=1)\n",
    "#     encoder.cuda()\n",
    "#     print(encoder)\n",
    "#     x_test, h = encoder(x_test)\n",
    "\n",
    "#     db = DecoderBlock(out_channels=1)\n",
    "#     db.cuda()\n",
    "#     x_test = db(x_test, h)\n",
    "\n",
    "#     print('the shape of output = ', x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for x in range(4-2, -1, -1):\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6913a215bbcc3bc7ae5e7590d1ced35ed5310329dabd281eb0a320ee4e5a02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
