{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://discuss.pytorch.org/t/unet-implementation/426\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=2,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=False,\n",
    "        batch_norm=False,\n",
    "        up_mode='upconv',\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        print(self.up_path)\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])  #bridge\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        # 136, 136\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        # (136 - 104)/2 = 16\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        # 136 - 104\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "        #[:, :, 16:(16+104), 16:(16+104)]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): UNetUpBlock(\n",
      "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv_block): UNetConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): UNetUpBlock(\n",
      "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv_block): UNetConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): UNetUpBlock(\n",
      "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv_block): UNetConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (3): UNetUpBlock(\n",
      "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv_block): UNetConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 570, 570]             640\n",
      "              ReLU-2         [-1, 64, 570, 570]               0\n",
      "            Conv2d-3         [-1, 64, 568, 568]          36,928\n",
      "              ReLU-4         [-1, 64, 568, 568]               0\n",
      "     UNetConvBlock-5         [-1, 64, 568, 568]               0\n",
      "            Conv2d-6        [-1, 128, 282, 282]          73,856\n",
      "              ReLU-7        [-1, 128, 282, 282]               0\n",
      "            Conv2d-8        [-1, 128, 280, 280]         147,584\n",
      "              ReLU-9        [-1, 128, 280, 280]               0\n",
      "    UNetConvBlock-10        [-1, 128, 280, 280]               0\n",
      "           Conv2d-11        [-1, 256, 138, 138]         295,168\n",
      "             ReLU-12        [-1, 256, 138, 138]               0\n",
      "           Conv2d-13        [-1, 256, 136, 136]         590,080\n",
      "             ReLU-14        [-1, 256, 136, 136]               0\n",
      "    UNetConvBlock-15        [-1, 256, 136, 136]               0\n",
      "           Conv2d-16          [-1, 512, 66, 66]       1,180,160\n",
      "             ReLU-17          [-1, 512, 66, 66]               0\n",
      "           Conv2d-18          [-1, 512, 64, 64]       2,359,808\n",
      "             ReLU-19          [-1, 512, 64, 64]               0\n",
      "    UNetConvBlock-20          [-1, 512, 64, 64]               0\n",
      "           Conv2d-21         [-1, 1024, 30, 30]       4,719,616\n",
      "             ReLU-22         [-1, 1024, 30, 30]               0\n",
      "           Conv2d-23         [-1, 1024, 28, 28]       9,438,208\n",
      "             ReLU-24         [-1, 1024, 28, 28]               0\n",
      "    UNetConvBlock-25         [-1, 1024, 28, 28]               0\n",
      "  ConvTranspose2d-26          [-1, 512, 56, 56]       2,097,664\n",
      "           Conv2d-27          [-1, 512, 54, 54]       4,719,104\n",
      "             ReLU-28          [-1, 512, 54, 54]               0\n",
      "           Conv2d-29          [-1, 512, 52, 52]       2,359,808\n",
      "             ReLU-30          [-1, 512, 52, 52]               0\n",
      "    UNetConvBlock-31          [-1, 512, 52, 52]               0\n",
      "      UNetUpBlock-32          [-1, 512, 52, 52]               0\n",
      "  ConvTranspose2d-33        [-1, 256, 104, 104]         524,544\n",
      "           Conv2d-34        [-1, 256, 102, 102]       1,179,904\n",
      "             ReLU-35        [-1, 256, 102, 102]               0\n",
      "           Conv2d-36        [-1, 256, 100, 100]         590,080\n",
      "             ReLU-37        [-1, 256, 100, 100]               0\n",
      "    UNetConvBlock-38        [-1, 256, 100, 100]               0\n",
      "      UNetUpBlock-39        [-1, 256, 100, 100]               0\n",
      "  ConvTranspose2d-40        [-1, 128, 200, 200]         131,200\n",
      "           Conv2d-41        [-1, 128, 198, 198]         295,040\n",
      "             ReLU-42        [-1, 128, 198, 198]               0\n",
      "           Conv2d-43        [-1, 128, 196, 196]         147,584\n",
      "             ReLU-44        [-1, 128, 196, 196]               0\n",
      "    UNetConvBlock-45        [-1, 128, 196, 196]               0\n",
      "      UNetUpBlock-46        [-1, 128, 196, 196]               0\n",
      "  ConvTranspose2d-47         [-1, 64, 392, 392]          32,832\n",
      "           Conv2d-48         [-1, 64, 390, 390]          73,792\n",
      "             ReLU-49         [-1, 64, 390, 390]               0\n",
      "           Conv2d-50         [-1, 64, 388, 388]          36,928\n",
      "             ReLU-51         [-1, 64, 388, 388]               0\n",
      "    UNetConvBlock-52         [-1, 64, 388, 388]               0\n",
      "      UNetUpBlock-53         [-1, 64, 388, 388]               0\n",
      "           Conv2d-54          [-1, 2, 388, 388]             130\n",
      "================================================================\n",
      "Total params: 31,030,658\n",
      "Trainable params: 31,030,658\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.25\n",
      "Forward/backward pass size (MB): 2474.88\n",
      "Params size (MB): 118.37\n",
      "Estimated Total Size (MB): 2594.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = UNet()\n",
    "model = model.to(device)\n",
    "summary(model, input_size=(1, 572, 572))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6913a215bbcc3bc7ae5e7590d1ced35ed5310329dabd281eb0a320ee4e5a02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
