{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BraveNet3D\n",
    "\n",
    "#Encoder\n",
    "\n",
    "from turtle import forward\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#kernels and stride to 3 × 3 × 3 and 1 for convolutions and 2 × 2 × 2 and 2 for max-pooling\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 1, padding = 1):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "    self.batch_norm = nn.BatchNorm3d(num_features=out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "    x = self.batch_norm(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, in_channels, model_depth = 4, pool_size = 2):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.root_feat_maps = 16\n",
    "    self.num_conv_block = 2\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth):\n",
    "      feat_map_channels = 2**(depth+1)*self.root_feat_maps #32, 64, 128, 256\n",
    "      \n",
    "\n",
    "      for i in range(self.num_conv_block):\n",
    "        if depth == 0:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels) \n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "        else:\n",
    "          self.conv_block = ConvBlock(in_channels=in_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "          if i == 1:\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels*2\n",
    "          else:\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "            in_channels, feat_map_channels = feat_map_channels, feat_map_channels\n",
    "\n",
    "      if depth == model_depth - 1:  #depth = 3\n",
    "        break\n",
    "      else:\n",
    "        nn.MaxPool3d\n",
    "        self.pooling = nn.MaxPool3d(kernel_size=pool_size, stride=2)\n",
    "        self.module_dict['max_pooling_{}'.format(depth)] = self.pooling\n",
    "\n",
    "    self.module_dict2 = self.module_dict\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    down_sampling_feature = []\n",
    "    down_sampling_feature2 = []\n",
    "    for k, op in self.module_dict.items():\n",
    "      # print('k: ', k, 'op: ', op)\n",
    "\n",
    "      if k.startswith('conv'):\n",
    "        # print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        # print ('output', x.shape)\n",
    "        if k.endswith('1'):\n",
    "          down_sampling_feature.append(x)\n",
    "\n",
    "      else:\n",
    "        # print ('input', x.shape)\n",
    "        x = op(x)\n",
    "        # print ('output', x.shape)\n",
    "        # print(k, x.shape)\n",
    "\n",
    "    for k, op in self.module_dict2.items():\n",
    "        if k.startswith('conv'):\n",
    "            y = op(y)\n",
    "            if k.endswith('1'):\n",
    "                down_sampling_feature2.append(y)\n",
    "        else:\n",
    "            y = op(y)\n",
    "\n",
    "    return down_sampling_feature, down_sampling_feature2\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs_low = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_low = inputs_low.cuda()\n",
    "\n",
    "    inputs_high = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_high = inputs_high.cuda()\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    encoder = Encoder(1)\n",
    "\n",
    "    # print(encoder)\n",
    "    encoder.cuda()\n",
    "\n",
    "\n",
    "    d_low, d_high = encoder(inputs_low, inputs_high)\n",
    "    # print('the shape of output = ', x_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = Encoder(1)\n",
    "# print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "\n",
    "class ConvTranspose(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    self.conv3d_transpose = nn.ConvTranspose3d(in_channels=in_channels, out_channels=out_channels,kernel_size=kernel_size,\n",
    "    stride=stride, padding=padding, output_padding = output_padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return(self.conv3d_transpose(x))\n",
    "\n",
    "class ConvBlock_One_ReLu(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0):\n",
    "    super(ConvBlock_One_ReLu, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv3D(x))\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class ConvBlock_One(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels, kernel_size = 1, stride = 1, padding = 0):\n",
    "    super(ConvBlock_One, self).__init__()\n",
    "    self.conv3D = nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv3D(x)\n",
    "\n",
    "    return(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, out_channels, model_depth = 4):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.num_conv_blocks = 2\n",
    "    self.num_feat_maps = 16\n",
    "    self.module_dict = nn.ModuleDict()\n",
    "\n",
    "    for depth in range(model_depth-1, -1, -1): #3, 2, 1, 0\n",
    "\n",
    "      feat_map_channels = 2**(depth+1)*self.num_feat_maps #256 ,128, 64, 32\n",
    "\n",
    "      if depth == 3:\n",
    "        for i in range(self.num_conv_blocks):\n",
    "          if i == 0:\n",
    "            self.conv_one = ConvBlock_One_ReLu(feat_map_channels*2, out_channels=feat_map_channels)\n",
    "            self.module_dict['conv_one_{}_{}'.format(depth, i)] = self.conv_one\n",
    "          else:\n",
    "            self.conv_one = ConvBlock_One_ReLu(feat_map_channels, out_channels=feat_map_channels)\n",
    "            self.module_dict['conv_one_{}_{}'.format(depth, i)] = self.conv_one\n",
    "\n",
    "        self.deconv = ConvTranspose(in_channels=feat_map_channels, out_channels=feat_map_channels) #256\n",
    "        self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "\n",
    "      else:  #depth = 2, 1, 0 feat_map_channels = 128, 64, 32\n",
    "        for i in range(self.num_conv_blocks):\n",
    "          if i == 0:\n",
    "            self.conv_block = ConvBlock(in_channels=feat_map_channels*4, out_channels=feat_map_channels) #512/128, 256/64, 128/32\n",
    "            self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "            self.dropout = nn.Dropout3d()\n",
    "            self.module_dict['dropout{}'.format(depth)] = self.dropout\n",
    "          else:\n",
    "            self.conv_block = ConvBlock(in_channels=feat_map_channels, out_channels=feat_map_channels) #128/128, 64/64, 32/32\n",
    "            self.module_dict['conv_{}_{}'.format(depth, i)] = self.conv_block\n",
    "\n",
    "        if depth != 0:\n",
    "          self.deconv = ConvTranspose(in_channels=feat_map_channels, out_channels=feat_map_channels)\n",
    "          self.module_dict['deconv_{}'.format(depth)] = self.deconv\n",
    "\n",
    "      if depth == 0:\n",
    "        self.final_conv = ConvBlock_One(in_channels=feat_map_channels, out_channels=out_channels)\n",
    "        self.module_dict['final_conv'] = self.final_conv\n",
    "\n",
    "  def forward(self, down_sampling_feature, down_sampling_feature2):\n",
    "\n",
    "    for k, op in self.module_dict.items():\n",
    "        if k.startswith('conv'):\n",
    "            if k.endswith('3_0'):\n",
    "                x = torch.cat((down_sampling_feature[3], down_sampling_feature2[3]), dim = 1)\n",
    "                print ('first concat_x.shape', x.shape) \n",
    "                x = op(x)\n",
    "                print ('operation: ',k, 'output shape: ', x.shape) \n",
    "            else:\n",
    "                x = op(x)\n",
    "                print ('operation: ',k, 'output shape: ', x.shape) \n",
    "        elif k.startswith('deconv'):  #deconv_3, deconv_2, deconv_1\n",
    "            x = op(x)\n",
    "            print ('operation: ',k, 'output shape: ', x.shape) \n",
    "            # print ('int(k[-1])', int(k[-1])) \n",
    "            layer = int(k[-1])-1 #2, 1, 0\n",
    "            y = torch.cat((down_sampling_feature[layer], down_sampling_feature2[layer]), dim = 1)\n",
    "            print ('concat_shape_1', y.shape) \n",
    "            x = torch.cat((x, y), dim = 1)\n",
    "            print ('x.concat shape', x.shape) \n",
    "        else:\n",
    "            x = op(x)\n",
    "            print ('operation: ',k, 'output shape: ', x.shape) \n",
    "\n",
    "    return x\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "\n",
    "#     decoder = Decoder(1)\n",
    "#     decoder.cuda()\n",
    "#     x = decoder(d_low, d_high)\n",
    "    \n",
    "#     print('the shape of output = ', x .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (module_dict): ModuleDict(\n",
       "    (conv_one_3_0): ConvBlock_One_ReLu(\n",
       "      (conv3D): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (conv_one_3_1): ConvBlock_One_ReLu(\n",
       "      (conv3D): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "    (deconv_3): ConvTranspose(\n",
       "      (conv3d_transpose): ConvTranspose3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "    (conv_2_0): ConvBlock(\n",
       "      (conv3D): Conv3d(512, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout2): Dropout3d(p=0.5, inplace=False)\n",
       "    (conv_2_1): ConvBlock(\n",
       "      (conv3D): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (deconv_2): ConvTranspose(\n",
       "      (conv3d_transpose): ConvTranspose3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "    (conv_1_0): ConvBlock(\n",
       "      (conv3D): Conv3d(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout1): Dropout3d(p=0.5, inplace=False)\n",
       "    (conv_1_1): ConvBlock(\n",
       "      (conv3D): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (deconv_1): ConvTranspose(\n",
       "      (conv3d_transpose): ConvTranspose3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "    )\n",
       "    (conv_0_0): ConvBlock(\n",
       "      (conv3D): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout0): Dropout3d(p=0.5, inplace=False)\n",
       "    (conv_0_1): ConvBlock(\n",
       "      (conv3D): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (final_conv): ConvBlock_One(\n",
       "      (conv3D): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (conv_one): ConvBlock_One_ReLu(\n",
       "    (conv3D): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       "  (deconv): ConvTranspose(\n",
       "    (conv3d_transpose): ConvTranspose3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  )\n",
       "  (conv_block): ConvBlock(\n",
       "    (conv3D): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (batch_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (dropout): Dropout3d(p=0.5, inplace=False)\n",
       "  (final_conv): ConvBlock_One(\n",
       "    (conv3D): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Decoder(1)\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first concat_x.shape torch.Size([1, 512, 1, 8, 8])\n",
      "operation:  conv_one_3_0 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "operation:  conv_one_3_1 output shape:  torch.Size([1, 256, 1, 8, 8])\n",
      "operation:  deconv_3 output shape:  torch.Size([1, 256, 2, 16, 16])\n",
      "concat_shape_1 torch.Size([1, 256, 2, 16, 16])\n",
      "x.concat shape torch.Size([1, 512, 2, 16, 16])\n",
      "operation:  conv_2_0 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation:  dropout2 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation:  conv_2_1 output shape:  torch.Size([1, 128, 2, 16, 16])\n",
      "operation:  deconv_2 output shape:  torch.Size([1, 128, 4, 32, 32])\n",
      "concat_shape_1 torch.Size([1, 128, 4, 32, 32])\n",
      "x.concat shape torch.Size([1, 256, 4, 32, 32])\n",
      "operation:  conv_1_0 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation:  dropout1 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation:  conv_1_1 output shape:  torch.Size([1, 64, 4, 32, 32])\n",
      "operation:  deconv_1 output shape:  torch.Size([1, 64, 8, 64, 64])\n",
      "concat_shape_1 torch.Size([1, 64, 8, 64, 64])\n",
      "x.concat shape torch.Size([1, 128, 8, 64, 64])\n",
      "operation:  conv_0_0 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation:  dropout0 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation:  conv_0_1 output shape:  torch.Size([1, 32, 8, 64, 64])\n",
      "operation:  final_conv output shape:  torch.Size([1, 1, 8, 64, 64])\n",
      "Final output shape:  torch.Size([1, 1, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class ContextUnet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, model_depth = 4, final_activation = 'sigmoid'):\n",
    "        super(ContextUnet, self).__init__()\n",
    "        self.encoder = Encoder(in_channels=in_channels, model_depth=model_depth)\n",
    "        self.decoder = Decoder(out_channels=out_channels, model_depth=model_depth)\n",
    "        if final_activation == 'sigmoid':\n",
    "            self.f_activation = nn.Sigmoid()\n",
    "        else:\n",
    "            self.f_activation = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        d_features, d_features2 = self.encoder(x, y)\n",
    "        x = self.decoder(d_features, d_features2)\n",
    "        x = self.f_activation(x)\n",
    "        print(\"Final output shape: \", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs_low = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_low = inputs_low.cuda()\n",
    "\n",
    "    inputs_high = torch.randn(1, 1, 8, 64, 64)\n",
    "    inputs_high = inputs_high.cuda()\n",
    "\n",
    "    # print('the shape of input = ', inputs.shape)\n",
    "\n",
    "    model = ContextUnet(in_channels=1, out_channels=1)\n",
    "    model.cuda()\n",
    "\n",
    "    x_test = model(inputs_low, inputs_high)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.4475, 0.5440, 0.5654,  ..., 0.3638, 0.6241, 0.4367],\n",
       "           [0.5357, 0.4622, 0.3724,  ..., 0.4390, 0.6015, 0.2745],\n",
       "           [0.3636, 0.4844, 0.5065,  ..., 0.4693, 0.6628, 0.3861],\n",
       "           ...,\n",
       "           [0.4565, 0.5578, 0.5475,  ..., 0.5738, 0.5020, 0.5477],\n",
       "           [0.5913, 0.5395, 0.3446,  ..., 0.4422, 0.6531, 0.4209],\n",
       "           [0.4872, 0.4813, 0.4483,  ..., 0.2595, 0.3753, 0.5534]],\n",
       "\n",
       "          [[0.3793, 0.3781, 0.4511,  ..., 0.4986, 0.3813, 0.5117],\n",
       "           [0.3602, 0.4761, 0.6450,  ..., 0.4184, 0.3597, 0.5232],\n",
       "           [0.6027, 0.7492, 0.6268,  ..., 0.5129, 0.5211, 0.5568],\n",
       "           ...,\n",
       "           [0.5250, 0.5006, 0.3647,  ..., 0.2646, 0.6313, 0.5253],\n",
       "           [0.6121, 0.2297, 0.6982,  ..., 0.5259, 0.4092, 0.5431],\n",
       "           [0.5163, 0.4656, 0.4025,  ..., 0.4765, 0.4122, 0.3629]],\n",
       "\n",
       "          [[0.5087, 0.3745, 0.3668,  ..., 0.2743, 0.3800, 0.3814],\n",
       "           [0.5692, 0.3851, 0.3346,  ..., 0.4671, 0.4983, 0.4166],\n",
       "           [0.4602, 0.5352, 0.5232,  ..., 0.3647, 0.4805, 0.3719],\n",
       "           ...,\n",
       "           [0.5794, 0.6461, 0.4172,  ..., 0.4859, 0.2433, 0.5046],\n",
       "           [0.5073, 0.6199, 0.5376,  ..., 0.5559, 0.4366, 0.5632],\n",
       "           [0.4670, 0.3591, 0.4259,  ..., 0.4811, 0.4628, 0.5032]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[0.4716, 0.6265, 0.2790,  ..., 0.4712, 0.3956, 0.3708],\n",
       "           [0.4761, 0.3539, 0.5207,  ..., 0.6705, 0.3150, 0.4930],\n",
       "           [0.3944, 0.5982, 0.5680,  ..., 0.3131, 0.4912, 0.5257],\n",
       "           ...,\n",
       "           [0.5777, 0.4323, 0.5584,  ..., 0.4553, 0.3031, 0.3991],\n",
       "           [0.4416, 0.5486, 0.4602,  ..., 0.5033, 0.6542, 0.6325],\n",
       "           [0.4024, 0.4990, 0.3674,  ..., 0.4533, 0.3926, 0.4210]],\n",
       "\n",
       "          [[0.5518, 0.4322, 0.3655,  ..., 0.4324, 0.6630, 0.5014],\n",
       "           [0.6549, 0.5380, 0.4929,  ..., 0.4796, 0.4971, 0.3992],\n",
       "           [0.4736, 0.6626, 0.3851,  ..., 0.3612, 0.4810, 0.5279],\n",
       "           ...,\n",
       "           [0.5675, 0.4322, 0.6863,  ..., 0.5283, 0.4623, 0.6117],\n",
       "           [0.4839, 0.5217, 0.6917,  ..., 0.3823, 0.3424, 0.5104],\n",
       "           [0.4151, 0.4678, 0.3207,  ..., 0.5621, 0.5664, 0.5077]],\n",
       "\n",
       "          [[0.3815, 0.4584, 0.6257,  ..., 0.2663, 0.4797, 0.4171],\n",
       "           [0.4905, 0.4923, 0.4671,  ..., 0.5378, 0.4542, 0.5036],\n",
       "           [0.3018, 0.3466, 0.5321,  ..., 0.6774, 0.4740, 0.5142],\n",
       "           ...,\n",
       "           [0.5315, 0.5334, 0.3623,  ..., 0.5031, 0.3767, 0.4574],\n",
       "           [0.2979, 0.4791, 0.4659,  ..., 0.4660, 0.3792, 0.5421],\n",
       "           [0.5245, 0.5211, 0.5764,  ..., 0.4300, 0.4248, 0.4163]]]]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6913a215bbcc3bc7ae5e7590d1ced35ed5310329dabd281eb0a320ee4e5a02d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
